{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00ab62-03aa-43ac-8cf5-b81a2e8bcd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import importlib\n",
    "sys.path.append('../')\n",
    "from utils_modules.models import SummaryNet, Expander, Net, vector_to_Cov\n",
    "from utils_modules.vicreg import vicreg_loss\n",
    "import utils_modules.data as utils_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e65e19d-6791-4d0c-8d4c-d94834911460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device; use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: %s'%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fbe791-d065-46af-abda-84a305ace287",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53133678-7404-411a-b3c1-cc6145502ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load maps and parameters\n",
    "maps      = np.load(...)[:, :, None, :, :]\n",
    "dset_size = maps.shape[0] # data set size\n",
    "splits    = maps.shape[1] # number of augmentations/views per parameter set\n",
    "\n",
    "params  = np.load(...)[:, None, :]\n",
    "params  = np.repeat(params, splits, axis = 1) # reshape the parameters to match the shape of the maps\n",
    "\n",
    "# pre-process the maps data set\n",
    "rescale     = True\n",
    "standardize = True\n",
    "verbose     = True\n",
    "\n",
    "if rescale:\n",
    "    maps = np.log(maps+1)\n",
    "if standardize:\n",
    "    maps_mean, maps_std = np.mean(maps, dtype=np.float64), np.std(maps, dtype=np.float64)\n",
    "    maps = (maps - maps_mean)/maps_std\n",
    "    \n",
    "if verbose:\n",
    "    print('Shape of parameters and maps:', params.shape, maps.shape)\n",
    "    print('Parameter 1 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 0].min(), params[:, :, 0].max()))\n",
    "    print('Parameter 2 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 1].min(), params[:, :, 1].max()))\n",
    "    \n",
    "    if rescale: print('Rescale: ', rescale)\n",
    "    if standardize: print('Standardize: ', standardize)\n",
    "\n",
    "maps   = torch.tensor(maps).float().to(device) \n",
    "params = torch.tensor(params).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0598e7-79c8-4390-a9bf-c69f3f500d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into train, validation, and test sets\n",
    "batch_size = 200\n",
    "train_frac, valid_frac, test_frac = 0.8, 0.1, 0.1\n",
    "\n",
    "\n",
    "train_dset, valid_dset, test_dset = utils_data.create_datasets(maps, params, \n",
    "                                                               train_frac, valid_frac, test_frac, \n",
    "                                                               seed = seed,\n",
    "                                                               rotations=True) \n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)\n",
    "test_loader  = DataLoader(test_dset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23456873-9863-4eb8-a762-7a0eec85a7a3",
   "metadata": {},
   "source": [
    "## Load the encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fa644d4-0652-4189-b5fa-7dced32b1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = ...\n",
    "fout   = ...\n",
    "\n",
    "hidden     = 8\n",
    "last_layer = 2*hidden\n",
    "\n",
    "n_params   = 2\n",
    "n_tril     = int(n_params * (n_params + 1) / 2)  # Number of parameters in lower triangular matrix, for symmetric matrix\n",
    "n_out      = n_params + n_tril  \n",
    "\n",
    "# load the encoder model\n",
    "model = SummaryNet(hidden = hidden, last_layer = last_layer).to(device)\n",
    "model.load_state_dict(torch.load(fmodel))\n",
    "model.eval(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b780c9-0029-49de-a268-d8e018c8ea23",
   "metadata": {},
   "source": [
    "## Convert maps into summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002ba0dd-2102-46fb-b09d-8fb066e280cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in train_loader:\n",
    "        x    = x.to(device=device)\n",
    "        y    = y.to(device=device)\n",
    "        x_NN = model(x).to(device=device)\n",
    "        \n",
    "        x_train.append(x_NN)\n",
    "        y_train.append(y)\n",
    "        \n",
    "    for x, y in valid_loader:\n",
    "        x    = x.to(device=device)\n",
    "        y    = y.to(device=device)\n",
    "        x_NN = model(x).to(device=device)\n",
    "        \n",
    "        x_valid.append(x_NN)\n",
    "        y_valid.append(y)\n",
    "\n",
    "############################\n",
    "x_train = torch.cat(x_train)\n",
    "y_train = torch.cat(y_train)\n",
    "\n",
    "train_dset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "############################\n",
    "\n",
    "x_valid = torch.cat(x_valid)\n",
    "y_valid = torch.cat(y_valid)\n",
    "\n",
    "valid_dset = TensorDataset(x_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a08d79-8251-4d75-ac79-aaf5e28ec3c5",
   "metadata": {},
   "source": [
    "## Downstream task: Parameter Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "152e6e05-3f02-457c-a35c-e0f490a694ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output files\n",
    "fmodel_lr = ...\n",
    "fout_lr   = ...\n",
    "\n",
    "# define the network model for the downstream task\n",
    "mlp_lr_units = [16*last_layer, 16*last_layer, n_out]\n",
    "lr_net = Expander(mlp_lr_units, last_layer, bn = True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b230057-de72-4cf9-8b65-74feed85bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr         = 1e-3\n",
    "epochs     = 200\n",
    "lr        = 5e-4 # 1e-3\n",
    "\n",
    "optimizer = torch.optim.AdamW(lr_net.parameters(), lr=lr, betas=(0.9, 0.999), \n",
    "                             eps=1e-8, amsgrad=False)  \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd22ef-a67a-4548-bf2c-6a1dc83a122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_net.eval()\n",
    "min_valid_loss, points = 0.0, 0\n",
    "for x, y in valid_loader:\n",
    "    with torch.no_grad():\n",
    "        x    = x.to(device=device)\n",
    "        y    = y.to(device=device)\n",
    "        y_NN = lr_net(x).to(device=device) \n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).to(device=device).mean()\n",
    "        \n",
    "        min_valid_loss += (loss.cpu().item())*x.shape[0]\n",
    "        points += x.shape[0]\n",
    "        \n",
    "min_valid_loss /= points\n",
    "if verbose:\n",
    "    print('Initial valid loss = %.3e'%min_valid_loss)\n",
    "# loop over the epochs\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # training\n",
    "    train_loss, num_points = 0.0, 0\n",
    "    lr_net.train()\n",
    "    for x,y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_NN = lr_net(x).to(device=device) \n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += (loss.cpu().item())*x.shape[0]\n",
    "        num_points += x.shape[0]\n",
    "        \n",
    "    train_loss = train_loss/num_points\n",
    "\n",
    "    # validation\n",
    "    valid_loss, num_points = 0.0, 0\n",
    "    lr_net.eval()\n",
    "    for x,y in valid_loader:\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)            \n",
    "            y_NN = lr_net(x).to(device=device) \n",
    "        \n",
    "            y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "            Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "            loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).mean()\n",
    "            \n",
    "            valid_loss += (loss.cpu().item())*x.shape[0]\n",
    "            num_points += x.shape[0]\n",
    "    valid_loss = valid_loss/num_points\n",
    "\n",
    "    # verbose\n",
    "    if valid_loss<min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(lr_net.state_dict(), fmodel_lr)\n",
    "        print('Epoch %d: %.3e %.3e (saving)'%(epoch, train_loss, valid_loss))\n",
    "    else:\n",
    "        print('Epoch %d: %.3e %.3e '%(epoch, train_loss, valid_loss))\n",
    "\n",
    "    if epoch == 0:\n",
    "        f = open(fout_lr, 'w')\n",
    "    else:\n",
    "        f = open(fout_lr, 'a')\n",
    "    f.write('%d %.4e %.4e\\n'%(epoch, train_loss, valid_loss))\n",
    "    f.close()\n",
    "    \n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dff4c2-0012-409b-8075-913efc6f3621",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "losses = np.loadtxt(fout_lr)\n",
    "start_epoch = 0\n",
    "end_epoch = 200\n",
    "plt.plot(losses[start_epoch:end_epoch, 0], losses[start_epoch:end_epoch, 1], label = 'Training loss')\n",
    "plt.plot(losses[start_epoch:end_epoch, 0], losses[start_epoch:end_epoch, 2], label = 'Validation loss')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3adf6ad-adbb-4cc0-8179-5a7a4bdfcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(fmodel))\n",
    "model.eval();\n",
    "\n",
    "lr_net.load_state_dict(torch.load(fmodel_lr))\n",
    "lr_net.eval(); \n",
    "\n",
    "test_loss, num_points = 0., 0\n",
    "params_true = []\n",
    "params_pred = []\n",
    "errors_pred = []\n",
    "with torch.no_grad(): \n",
    "    for x, y in test_loader:\n",
    "        x = x.float()\n",
    "        y = y.float()[:, [0, 1]]\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        y_NN = lr_net(model(x))\n",
    "        \n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y, covariance_matrix=Cov).log_prob(y_pred).mean()\n",
    "        \n",
    "        test_loss += (loss.cpu().item())*x.shape[0]\n",
    "        num_points += x.shape[0]\n",
    "        \n",
    "        params_true.append(y)\n",
    "        params_pred.append(y_pred)\n",
    "        errors_pred.append(Cov)\n",
    "    \n",
    "    test_loss = test_loss/num_points\n",
    "print('Test loss: ', test_loss)\n",
    "\n",
    "params_true = torch.cat(params_true)\n",
    "params_pred = torch.cat(params_pred)  \n",
    "errors_pred = torch.cat(errors_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6ff84-8cda-4844-81ec-b2989a998460",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_error = F.mse_loss(params_true[:, :2], params_pred[:, :2]).cpu().numpy()\n",
    "print('MSE error: {:}'.format(MSE_error))\n",
    "MSE_error = F.mse_loss(params_true[:, :1], params_pred[:, :1]).cpu().numpy()\n",
    "print('MSE error on OmegaM: {:}'.format(MSE_error))\n",
    "MSE_error = F.mse_loss(params_true[:, 1:], params_pred[:, 1:]).cpu().numpy()\n",
    "print('MSE error on sigma8: {:}'.format(MSE_error))\n",
    "\n",
    "print('\\nActual errors on A, B (relative, %)')\n",
    "print((torch.abs(params_pred[:, :1] - params_true[:, :1])/params_true[:, :1]).mean()*100)\n",
    "print((torch.abs(params_pred[:, 1:] - params_true[:, 1:])/params_true[:, 1:]).mean()*100)\n",
    "\n",
    "print('\\nPredicted errors on A, B (relative, %)')\n",
    "print((torch.sqrt(errors_pred[:, 0, 0])/params_pred[:, :1]).mean()*100)\n",
    "print((torch.sqrt(errors_pred[:, 1, 1])/params_pred[:, 1:]).mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e0e0d-f31d-414d-b106-b2c42dbd5a12",
   "metadata": {},
   "source": [
    "## Make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72dfe17-595c-4f01-8b21-7c087d764e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_pred_plot = params_pred.cpu().numpy()\n",
    "params_true_plot = params_true.cpu().numpy()\n",
    "errors_pred_plot = errors_pred.cpu().numpy()\n",
    "\n",
    "params_unique, indices_unique = np.unique(params_pred_plot[:, 0], return_index=True)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(indices_unique)\n",
    "indices_unique = indices_unique[:100]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axs[0].set_ylabel('Predicted ' + r'$\\Omega_M$')\n",
    "axs[0].set_xlabel('True ' + r'$\\Omega_M$')\n",
    "axs[0].plot([0.15, 0.45], [0.15, 0.45], c = 'k', lw = 2, ls = '--')\n",
    "axs[0].errorbar(params_true_plot[indices_unique, 0], params_pred_plot[indices_unique, 0], \n",
    "               yerr=np.sqrt(errors_pred_plot[indices_unique, 0, 0]), \n",
    "                linestyle = '', capsize = 2, label = r'$1\\sigma$')\n",
    "axs[0].set_aspect('equal')\n",
    "axs[0].legend(loc = 'upper left')\n",
    "\n",
    "axs[1].set_ylabel('Predicted ' + r'$\\sigma_8$')\n",
    "axs[1].set_xlabel('True ' + r'$\\sigma_8$')\n",
    "axs[1].plot([0.65, 0.95], [0.65, 0.95], c = 'k', lw = 2, ls = '--')\n",
    "axs[1].errorbar(params_true_plot[indices_unique, 1], params_pred_plot[indices_unique, 1], \n",
    "               yerr=np.sqrt(errors_pred_plot[indices_unique, 1, 1]), \n",
    "                linestyle = '', capsize = 2, label = r'$1\\sigma$')\n",
    "axs[1].set_aspect('equal')\n",
    "axs[1].legend(loc = 'upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f508a3-073b-429b-b878-0f4ea1d68726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_supervised_env",
   "language": "python",
   "name": "self_supervised_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
