{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba14eb5-f86e-4d2d-a732-54b426d9ec85",
   "metadata": {},
   "source": [
    "## (1) Packages and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9f58c-a2c2-4625-b22f-64efd3813380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import importlib\n",
    "sys.path.append('../')\n",
    "from utils_modules.models import SummaryNet, Expander, Net, vector_to_Cov\n",
    "from utils_modules.vicreg import vicreg_loss\n",
    "import utils_modules.data as utils_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90604c9c-6e44-4d66-bd57-1597ceaf836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for plots\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "rcnew = {\"mathtext.fontset\" : \"cm\", \n",
    "         \"xtick.labelsize\" : 18,\n",
    "         \"ytick.labelsize\" : 18,\n",
    "         \"axes.titlesize\" : 26, \n",
    "         \"axes.labelsize\" : 22,\n",
    "         \"xtick.major.size\" : 8,      \n",
    "         \"xtick.minor.size\" : 4,     \n",
    "         \"ytick.major.size\" : 8,      \n",
    "         \"ytick.minor.size\" : 4,      \n",
    "         \"legend.fontsize\" : 22,\n",
    "         'figure.titlesize' : 30,\n",
    "         'errorbar.capsize' : 4,\n",
    "         'axes.xmargin': 0.05,\n",
    "          'axes.ymargin': 0.05,\n",
    "        }\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "#plt.rcParams.update({\"text.usetex\": True,})\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374969e-b99d-4bcc-80a4-844df3c3deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPUs if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: %s'%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50384ec-f72a-4ff0-b2c9-9ca9c10c1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from nflows import distributions as distributions_\n",
    "from nflows import flows, transforms\n",
    "from nflows.nn import nets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75efe9f5-7ab2-40de-beb1-6f095f2eb942",
   "metadata": {},
   "source": [
    "## (2) Load and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9663a-2211-4ba8-bd18-651762e257b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load maps and parameters\n",
    "maps      = np.load(...)[:, :, None, :, :]\n",
    "dset_size = maps.shape[0] # data set size\n",
    "splits    = maps.shape[1] # number of augmentations/views per parameter set\n",
    "\n",
    "params  = np.load(...)[:, None, :]\n",
    "params  = np.repeat(params, splits, axis = 1) # reshape the parameters to match the shape of the maps\n",
    "\n",
    "# pre-process the maps data set\n",
    "rescale     = True\n",
    "standardize = True\n",
    "verbose     = True\n",
    "\n",
    "if rescale:\n",
    "    maps = np.log(maps+1)\n",
    "if standardize:\n",
    "    maps_mean, maps_std = np.mean(maps, dtype=np.float64), np.std(maps, dtype=np.float64)\n",
    "    maps = (maps - maps_mean)/maps_std\n",
    "    \n",
    "if verbose:\n",
    "    print('Shape of parameters and maps:', params.shape, maps.shape)\n",
    "    print('Parameter 1 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 0].min(), params[:, :, 0].max()))\n",
    "    print('Parameter 2 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 1].min(), params[:, :, 1].max()))\n",
    "    \n",
    "    if rescale: print('Rescale: ', rescale)\n",
    "    if standardize: print('Standardize: ', standardize)\n",
    "\n",
    "maps   = torch.tensor(maps).float().to(device) \n",
    "params = torch.tensor(params).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8403b09-7612-450e-9670-b49e80ed0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into train, validation, and test sets\n",
    "batch_size = 256\n",
    "train_frac, valid_frac, test_frac = 0.8, 0.1, 0.1\n",
    "\n",
    "\n",
    "train_dset, valid_dset, test_dset = utils_data.create_datasets(maps, params, \n",
    "                                                               train_frac, valid_frac, test_frac, \n",
    "                                                               seed = seed,\n",
    "                                                               rotations=False) \n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)\n",
    "test_loader  = DataLoader(test_dset, batch_size, shuffle = False)\n",
    "\n",
    "if verbose: print('Split the data into train, validation, and test sets.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23456873-9863-4eb8-a762-7a0eec85a7a3",
   "metadata": {},
   "source": [
    "## (3) Load the encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b451ff11-2608-4d0b-a5a8-77d55cca30bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Encoder Network \n",
    "fmodel = ...\n",
    "fout   = ...\n",
    "\n",
    "hidden     = 8         # architecture parameters \n",
    "last_layer = 2*hidden\n",
    "\n",
    "model = SummaryNet(hidden = hidden, last_layer = last_layer).to(device)\n",
    "model.load_state_dict(torch.load(fmodel, map_location=torch.device(device)))\n",
    "model.eval(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3af930f-b7b9-40c6-8b22-eff6ae993af1",
   "metadata": {},
   "source": [
    "## (4) Get the summaries from the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03337e7-082b-4870-b933-536077647d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "with torch.no_grad():\n",
    "    for x, y in train_loader:\n",
    "        x    = x.to(device=device)\n",
    "        y    = y.to(device=device)\n",
    "        x_NN = model(x).to(device=device)\n",
    "        \n",
    "        x_train.append(x_NN)\n",
    "        y_train.append(y)\n",
    "        \n",
    "    for x, y in valid_loader:\n",
    "        x    = x.to(device=device)\n",
    "        y    = y.to(device=device)\n",
    "        x_NN = model(x).to(device=device)\n",
    "        \n",
    "        x_valid.append(x_NN)\n",
    "        y_valid.append(y)\n",
    "        \n",
    "    for x, y in test_loader:\n",
    "        x    = x.to(device=device)\n",
    "        y    = y.to(device=device)\n",
    "        x_NN = model(x).to(device=device)\n",
    "        \n",
    "        x_test.append(x_NN)\n",
    "        y_test.append(y)\n",
    "\n",
    "############################\n",
    "x_train = torch.cat(x_train)\n",
    "y_train = torch.cat(y_train)\n",
    "\n",
    "train_dset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "############################\n",
    "\n",
    "x_valid = torch.cat(x_valid)\n",
    "y_valid = torch.cat(y_valid)\n",
    "\n",
    "valid_dset = TensorDataset(x_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)\n",
    "############################\n",
    "x_test = torch.cat(x_test)\n",
    "y_test = torch.cat(y_test)\n",
    "\n",
    "test_dset = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_dset, batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cdab0b-1400-4caa-8d42-1c754a6ba7e8",
   "metadata": {},
   "source": [
    "## (5) Build and train a normalizing flow to predict $\\Omega_M$ and $\\sigma_8$ from the summaries\n",
    "### (without assuming that these parameters follow a Gaussian distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a508cf2-1414-4329-9879-d290a83f19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_maf(dim=1, num_transforms=8, context_features=None, hidden_features=128):\n",
    "    transform = transforms.CompositeTransform(\n",
    "        [\n",
    "            transforms.CompositeTransform(\n",
    "                [\n",
    "                    transforms.MaskedAffineAutoregressiveTransform(\n",
    "                        features=dim,\n",
    "                        hidden_features=hidden_features,\n",
    "                        context_features=context_features,\n",
    "                        num_blocks=2,\n",
    "                        use_residual_blocks=False,\n",
    "                        random_mask=False,\n",
    "                        activation=torch.tanh,\n",
    "                        dropout_probability=0.0,\n",
    "                        use_batch_norm=False,\n",
    "                    ),\n",
    "                    transforms.RandomPermutation(features=dim),\n",
    "                ]\n",
    "            )\n",
    "            for _ in range(num_transforms)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    distribution = distributions_.StandardNormal((dim,))\n",
    "    neural_net = flows.Flow(transform, distribution)\n",
    "\n",
    "    return neural_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0c522-56c3-43ab-95df-23e147b5c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output files\n",
    "fmodel = ...\n",
    "fout   = ...\n",
    "\n",
    "num_transforms   = 8\n",
    "hidden_features  = 128\n",
    "\n",
    "flow_net = build_maf(dim=2, context_features=2,\n",
    "                     num_transforms=num_transforms,\n",
    "                     hidden_features=hidden_features).to(device=device)\n",
    "\n",
    "lr         = 5e-4\n",
    "max_epochs = 300\n",
    "optimizer = torch.optim.AdamW(flow_net.parameters(), \n",
    "                              lr=lr,\n",
    "                              weight_decay=1e-5,)  \n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                       T_max=max_epochs, \n",
    "                                                       verbose=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae22ee33-2c7c-4eac-90b2-566451b00b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_net.eval()\n",
    "min_valid_loss, points = 0.0, 0\n",
    "for x, y in valid_loader:\n",
    "    with torch.no_grad():\n",
    "        x    = x.float().to(device=device)\n",
    "        y    = y.float().to(device=device)\n",
    "        bs   = x.shape[0]\n",
    "        \n",
    "        loss = -flow_net.log_prob(y, context = x).mean() \n",
    "        \n",
    "        min_valid_loss += (loss.cpu().item())*bs\n",
    "        points += bs\n",
    "    min_valid_loss /= points\n",
    "\n",
    "print('Initial valid loss = %.3e'%min_valid_loss)\n",
    "# do a loop over all the epochs\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    # training\n",
    "    train_loss, num_points = 0.0, 0\n",
    "    flow_net.train()\n",
    "    for x,y in train_loader:\n",
    "        x    = x.float().to(device=device)\n",
    "        y    = y.float().to(device=device)\n",
    "        bs   = x.shape[0]\n",
    "        \n",
    "        loss =  -flow_net.log_prob(y, context = x).mean() \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += (loss.cpu().item())*bs\n",
    "        num_points += bs\n",
    "        \n",
    "    train_loss = train_loss/num_points\n",
    "\n",
    "    # validation\n",
    "    valid_loss, num_points = 0.0, 0\n",
    "    flow_net.eval()\n",
    "    for x,y in valid_loader:\n",
    "        with torch.no_grad():\n",
    "            x    = x.float().to(device=device)\n",
    "            y    = y.float().to(device=device)\n",
    "            bs   = x.shape[0]\n",
    " \n",
    "            loss = -flow_net.log_prob(y, context = x).mean() \n",
    "            \n",
    "            valid_loss += (loss.cpu().item())*bs\n",
    "            num_points += bs\n",
    "    valid_loss = valid_loss/num_points\n",
    "\n",
    "    # verbose\n",
    "    if valid_loss<min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(flow_net.state_dict(), fmodel)\n",
    "        print('Epoch %d: %.3e %.3e (saving)'%(epoch, train_loss, valid_loss))\n",
    "    else:\n",
    "        print('Epoch %d: %.3e %.3e '%(epoch, train_loss, valid_loss))\n",
    "\n",
    "    if epoch == 0:\n",
    "        f = open(fout, 'w')\n",
    "    else:\n",
    "        f = open(fout, 'a')\n",
    "    f.write('%d %.4e %.4e\\n'%(epoch, train_loss, valid_loss))\n",
    "    f.close()\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9049ce7-d01f-4597-9da6-167853885da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.figure(figsize = (10, 6))\n",
    "losses = np.loadtxt(fout)\n",
    "start_epoch = 5\n",
    "end_epoch = -1\n",
    "plt.plot(losses[start_epoch:end_epoch, 0], \n",
    "         losses[start_epoch:end_epoch, 1], label = 'Training loss')\n",
    "plt.plot(losses[start_epoch:end_epoch, 0], losses[start_epoch:end_epoch, 2], label = 'Validation loss')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbe8cf-0f2d-446a-b921-edb4a42d2bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_supervised_env",
   "language": "python",
   "name": "self_supervised_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
