{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2143a050-2e1b-4848-8365-a129f8834222",
   "metadata": {},
   "source": [
    "## (1) Packages and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10daa2d-ff3a-48f2-a0b8-16b6102bc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math, importlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm \n",
    "from scipy import linalg\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.covariance import GraphicalLassoCV, LedoitWolf, EmpiricalCovariance, MinCovDet, ShrunkCovariance\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal as Normal\n",
    "from torch import tensor, as_tensor, Tensor, eye, zeros, ones, float32\n",
    "\n",
    "\n",
    "import pyccl as ccl\n",
    "import powerbox as pbox\n",
    "\n",
    "from sbi.analysis import run_sbc, sbc_rank_plot\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils_modules.models import SummaryNet, Expander, vector_to_Cov\n",
    "from utils_modules.vicreg import vicreg_loss\n",
    "import utils_modules.data as utils_data\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nflows import distributions as distributions_\n",
    "from nflows import flows, transforms\n",
    "from nflows.nn import nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57192a98-24a1-4a37-a5ec-4bfd27759f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for plots\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "rcnew = {\"mathtext.fontset\" : \"cm\", \n",
    "         \"xtick.labelsize\" : 10,\n",
    "         \"ytick.labelsize\" : 10,\n",
    "         \"axes.titlesize\" : 26, \n",
    "         \"axes.labelsize\" : 14,\n",
    "         \"xtick.major.size\" : 8,      \n",
    "         \"xtick.minor.size\" : 4,      \n",
    "         \"ytick.major.size\" : 8,      \n",
    "         \"ytick.minor.size\" : 4,      \n",
    "         \"legend.fontsize\" : 22,\n",
    "         'figure.titlesize' : 30,\n",
    "         'errorbar.capsize' : 4,\n",
    "         'axes.xmargin': 0.05,\n",
    "          'axes.ymargin': 0.05,\n",
    "        }\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d5dea-13a3-450d-af4e-ffb21b5eb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select device; use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: %s'%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92fffc9-1462-402c-8f5b-0770caab23a3",
   "metadata": {},
   "source": [
    "## (2) Define functions to compute coverage\n",
    "\n",
    "Code adopted from https://github.com/mackelab/tsnpe_neurips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75b8b9-7686-4dcf-9f56-578bfb51eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rank(val, vec):\n",
    "    c = torch.cat([vec, val])\n",
    "    s = torch.argsort(c)\n",
    "    ind = torch.where(s == len(c) - 1)\n",
    "    return ind[0]  # .where returns a tuple\n",
    "\n",
    "# Compute coverage for an arbitrary posterior\n",
    "def compute_coverage(posterior, theta_proposal, x_proposal, num_monte_carlo= 1_000, alpha=torch.linspace(0, 1, 20)):\n",
    "    gt_is_covered = zeros(alpha.shape)\n",
    "    counter = 0\n",
    "    for params, summstats in zip(theta_proposal, x_proposal):\n",
    "        xo = as_tensor(np.asarray([summstats]), dtype=float32)\n",
    "        posterior.set_default_x(xo)\n",
    "        lprobs = posterior.log_prob(\n",
    "                    posterior.sample((num_monte_carlo,), show_progress_bars=False)\n",
    "                )\n",
    "        gt_log_prob = posterior.log_prob(\n",
    "                    as_tensor(np.asarray([params]), dtype=float32)\n",
    "                )\n",
    "        rank_of_gt = compute_rank(gt_log_prob, lprobs)\n",
    "        norm_rank = rank_of_gt / lprobs.shape[0]\n",
    "        covered_in_alpha_quantile = norm_rank > alpha\n",
    "        gt_is_covered += covered_in_alpha_quantile.float()\n",
    "        counter += 1\n",
    "        if counter % 100 == 0: \n",
    "            print('# of samples examined: ', counter)\n",
    "    gt_is_covered /= x_proposal.shape[0]\n",
    "    return torch.flip(gt_is_covered, dims=[0])\n",
    "    \n",
    "# Compute coverage for the multivariate normal distribution \n",
    "# which is predicted by the inference network trained on VICReg summaries\n",
    "def compute_coverage_normal(theta_true, theta_pred, Cov_pred, \n",
    "                            num_monte_carlo= 1_000, \n",
    "                            alpha=torch.linspace(0, 1, 20)):\n",
    "    gt_is_covered = zeros(alpha.shape).to(device=device)\n",
    "    counter = 0\n",
    "    for params_true, params_pred, cov_pred in zip(theta_true, theta_pred, Cov_pred):\n",
    "        # get predicted posterior (multivariate normal)\n",
    "        posterior = Normal(loc=params_pred, covariance_matrix=cov_pred)\n",
    "        \n",
    "        # sample the posterior\n",
    "        posterior_samples = posterior.sample((num_monte_carlo,))\n",
    "        \n",
    "        # get log_probabilities of the samples\n",
    "        lprobs = posterior.log_prob(posterior_samples)\n",
    "        \n",
    "        # get log_probabilities of the true value\n",
    "        gt_log_prob = torch.atleast_1d(posterior.log_prob(params_true))\n",
    "\n",
    "\n",
    "        rank_of_gt = compute_rank(gt_log_prob, lprobs)\n",
    "        norm_rank = rank_of_gt / lprobs.shape[0]\n",
    "        #print(norm_rank.device, alpha.device)\n",
    "        covered_in_alpha_quantile = norm_rank > alpha\n",
    "        gt_is_covered += covered_in_alpha_quantile.float()\n",
    "        counter += 1\n",
    "        if counter % 100 == 0: \n",
    "            print('# of samples examined: ', counter)\n",
    "    gt_is_covered /= theta_true.shape[0]\n",
    "    return torch.flip(gt_is_covered, dims=[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ceaba-5829-4108-a16a-4a394e08d7b0",
   "metadata": {},
   "source": [
    "## (2) VICReg \n",
    "### (2.1) Load VICReg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec428c5-e0c6-4dd5-8339-bc71cbe13f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = ...\n",
    "fout   = ...\n",
    "\n",
    "hidden     = 8\n",
    "last_layer = 2*hidden\n",
    "\n",
    "n_params   = 2\n",
    "n_tril     = int(n_params * (n_params + 1) / 2)  # Number of parameters in lower triangular matrix, for symmetric matrix\n",
    "n_out      = n_params + n_tril  \n",
    "\n",
    "# load the encoder model\n",
    "model = SummaryNet(hidden = hidden, last_layer = last_layer).to(device)\n",
    "model.load_state_dict(torch.load(fmodel))\n",
    "model.eval(); \n",
    "\n",
    "# output files\n",
    "fmodel_lr = ...\n",
    "fout_lr   = ...\n",
    "\n",
    "# define the network model for the downstream task\n",
    "mlp_lr_units = [16*last_layer, 16*last_layer, n_out]\n",
    "lr_net = Expander(mlp_lr_units, last_layer, bn = True).to(device)\n",
    "# load the inference network model\n",
    "lr_net.load_state_dict(torch.load(fmodel_lr))\n",
    "lr_net.eval(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0403e4-5d01-4e8d-8d85-032b241522be",
   "metadata": {},
   "source": [
    "### (2.2) Load VICReg test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d150133-0274-4310-ab0a-0f299b3a7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load maps and parameters used for training\n",
    "maps      = np.load(...)[:, :, None, :, :]\n",
    "dset_size = maps.shape[0] # data set size\n",
    "splits    = maps.shape[1] # number of realizations per parameter set\n",
    "\n",
    "params  = np.load(...)[:, None, :]\n",
    "params  = np.repeat(params, splits, axis = 1) # reshape the parameters to match the shape of the maps\n",
    "\n",
    "# pre-process the maps data set\n",
    "rescale     = True\n",
    "standardize = True\n",
    "\n",
    "if rescale:\n",
    "    maps = np.log(maps+1)\n",
    "if standardize:\n",
    "    maps_mean, maps_std = np.mean(maps, dtype=np.float64), np.std(maps, dtype=np.float64)\n",
    "    maps = (maps - maps_mean)/maps_std\n",
    "    \n",
    "if verbose:\n",
    "    print('Shape of parameters and maps:', params.shape, maps.shape)\n",
    "    print('Parameter 1 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 0].min(), params[:, :, 0].max()))\n",
    "    print('Parameter 2 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 1].min(), params[:, :, 1].max()))\n",
    "    \n",
    "    if rescale: print('Rescale: ', rescale)\n",
    "    if standardize: print('Standardize: ', standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e909ebf-f5f5-486f-9145-a0f7543822d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maps_arr(params, splits, \n",
    "                 maps_mean, maps_std,\n",
    "                 BoxSize = 1000.0, Npixel = 100):\n",
    "    \n",
    "    OmegaM = params[0]\n",
    "    sigma8 = params[1]\n",
    "\n",
    "    OmegaB = 0.05\n",
    "    OmegaC = OmegaM - OmegaB\n",
    "    h    = 0.7\n",
    "    ns   = 0.96\n",
    "    \n",
    "    cosmo_ccl = ccl.Cosmology(Omega_c=OmegaC, Omega_b=OmegaB, \n",
    "                          h=h, sigma8 = sigma8, n_s=ns, \n",
    "                          transfer_function='eisenstein_hu')\n",
    "    \n",
    "    dfs_2D_splits = []\n",
    "    \n",
    "    for j in range(splits):\n",
    "        # generate a 2D Gaussian field\n",
    "        pb = pbox.PowerBox(\n",
    "            N=Npixel,                     \n",
    "            dim=2,                        \n",
    "            pk = lambda k_val: ccl.linear_matter_power(cosmo_ccl, k_val, 1.0)/BoxSize, \n",
    "            boxlength = BoxSize,           \n",
    "            seed = j,                \n",
    "        )\n",
    "        \n",
    "        # convert it to a lognormal field\n",
    "        delta_g = pb.delta_x()\n",
    "        var_g = np.var(delta_g)\n",
    "        rho_ln = np.exp(delta_g - var_g/2)\n",
    "        \n",
    "        dfs_2D_splits.append(rho_ln - 1)\n",
    "        \n",
    "    dfs_2D = np.array(dfs_2D_splits)[:, None, :, :]\n",
    "    dfs_2D = np.log(dfs_2D+1)\n",
    "    dfs_2D = (dfs_2D - maps_mean)/maps_std\n",
    "    return dfs_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1592d-f5ea-4a24-b93b-2ecf58fbfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set fiducial cosmological parameters\n",
    "params = np.array([0.3, 0.8])\n",
    "\n",
    "# generate maps to estimate covariance matrix for VICReg summaries\n",
    "dfs_2D = get_maps_arr(params, splits = 1_000, \n",
    "                      maps_mean = maps_mean, maps_std = maps_std)\n",
    "# compute inferred parameters (means and covariance) from the maps\n",
    "model_encoder.eval()\n",
    "with torch.no_grad(): \n",
    "    x = torch.tensor(dfs_2D).float().to(device)\n",
    "    representations = model_encoder(x) \n",
    "    inferred_params = inference_net(representations) \n",
    "    \n",
    "    y_pred, cov_pred = inferred_params[:, :n_params], inferred_params[:, n_params:]\n",
    "    Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622ddd5-3261-4be3-8551-d5aa070c6d62",
   "metadata": {},
   "source": [
    "### (2.3) Compute and plot coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5ff3e-bc65-45ef-b1c8-c818b05138fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = torch.linspace(0, 1, 20).to(device=device)\n",
    "\n",
    "thetas = torch.tensor([params]).repeat(1000, 1).to(device=device)\n",
    "coverage_arr = compute_coverage_normal(thetas, y_pred, Cov, num_monte_carlo= 1_000, alpha=alpha)\n",
    "\n",
    "plt.plot(figsize=(10, 10))\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.plot(alpha.cpu(), alpha.cpu(), c = 'k', ls = '--')\n",
    "plt.plot(alpha.cpu(), coverage_arr.cpu(),  \n",
    "         c = 'coral', label = 'VICReg', lw=2)\n",
    "plt.xlabel('Confidence level')\n",
    "plt.ylabel('Empirical coverage')\n",
    "plt.legend(loc = 'best', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209a852-eccb-400e-be0f-9b2ed9f3125e",
   "metadata": {},
   "source": [
    "## (3) Emulator + SBI\n",
    "\n",
    "### (3.1) Load the emulator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06467199-6691-42d1-a17b-c2b7acb57c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_maf(dim=1, num_transforms=8, context_features=None, hidden_features=128):\n",
    "    transform = transforms.CompositeTransform(\n",
    "        [\n",
    "            transforms.CompositeTransform(\n",
    "                [\n",
    "                    transforms.MaskedAffineAutoregressiveTransform(\n",
    "                        features=dim,\n",
    "                        hidden_features=hidden_features,\n",
    "                        context_features=context_features,\n",
    "                        num_blocks=2,\n",
    "                        use_residual_blocks=False,\n",
    "                        random_mask=False,\n",
    "                        activation=torch.tanh,\n",
    "                        dropout_probability=0.0,\n",
    "                        use_batch_norm=False,\n",
    "                    ),\n",
    "                    transforms.RandomPermutation(features=dim),\n",
    "                ]\n",
    "            )\n",
    "            for _ in range(num_transforms)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    distribution = distributions_.StandardNormal((dim,))\n",
    "    neural_net = flows.Flow(transform, distribution)\n",
    "\n",
    "    return neural_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8965e0c3-675f-4f6a-900c-69625e32f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the emulator model\n",
    "fmodel = ...\n",
    "\n",
    "last_layer = 16\n",
    "flow_net = build_maf(dim=last_layer, context_features=2).to(device=device)\n",
    "flow_net.load_state_dict(torch.load(fmodel, map_location=torch.device(device)))\n",
    "flow_net.eval(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c83f6-2cf4-4225-9245-c52e56cfc788",
   "metadata": {},
   "source": [
    "### (3.2) Load posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac153cc-6d58-4170-9344-e6a7db5e514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([0.3, 0.8])\n",
    "OmegaM, sigma8 = params[0], params[1]\n",
    "\n",
    "posterior = pickle.load(open(.., \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761bbd2-4378-425f-b429-204846a7f3e1",
   "metadata": {},
   "source": [
    "### (3.3) Get training data, compute and plot coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37516a18-cc42-400a-b65c-207a2234c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = torch.tensor([[OmegaM, sigma8]]).repeat(1000, 1)\n",
    "xs  = flow_net.sample(num_samples=1, context=thetas.to(device=device)).cpu().detach()[:, 0, :]\n",
    "\n",
    "alpha = torch.linspace(0, 1, 20)\n",
    "coverage_arr = compute_coverage(posterior, thetas.numpy(), xs.numpy(), alpha=alpha)\n",
    "\n",
    "plt.plot(figsize=(10, 10))\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.plot(alpha, alpha, c = 'k', ls = '--')\n",
    "plt.plot(alpha, coverage_arr,  \n",
    "         c = 'teal', label = 'Emulator + SBI')\n",
    "plt.xlabel('Confidence level')\n",
    "plt.ylabel('Empirical coverage')\n",
    "plt.legend(loc='best', fontsize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a835f9c-a64b-4fb5-af8d-71349d649ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
