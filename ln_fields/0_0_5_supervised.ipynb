{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757e8856-03c7-4e62-9983-738be5fe69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils_modules.models import SummaryNet, Expander, Net, NetEquivalent, vector_to_Cov\n",
    "from utils_modules.vicreg import vicreg_loss\n",
    "import utils_modules.data as utils_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c3c973-b220-4776-a6dd-ac076422722a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# select device; use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: %s'%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4ecca-6c6e-478b-9346-9ee91b62f7f3",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a42bdd-3369-43d8-b6f8-c75f65c68596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load maps and parameters\n",
    "maps      = np.load(...)[:, :, None, :, :]\n",
    "dset_size = maps.shape[0] # data set size\n",
    "splits    = maps.shape[1] # number of augmentations/views per parameter set\n",
    "\n",
    "params  = np.load(...)[:, None, :]\n",
    "params  = np.repeat(params, splits, axis = 1) # reshape the parameters to match the shape of the maps\n",
    "\n",
    "# pre-process the maps data set\n",
    "rescale     = True\n",
    "standardize = True\n",
    "verbose     = True\n",
    "\n",
    "if rescale:\n",
    "    maps = np.log(maps+1)\n",
    "if standardize:\n",
    "    maps_mean, maps_std = np.mean(maps, dtype=np.float64), np.std(maps, dtype=np.float64)\n",
    "    maps = (maps - maps_mean)/maps_std\n",
    "    \n",
    "if verbose:\n",
    "    print('Shape of parameters and maps:', params.shape, maps.shape)\n",
    "    print('Parameter 1 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 0].min(), params[:, :, 0].max()))\n",
    "    print('Parameter 2 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 1].min(), params[:, :, 1].max()))\n",
    "    \n",
    "    if rescale: print('Rescale: ', rescale)\n",
    "    if standardize: print('Standardize: ', standardize)\n",
    "\n",
    "maps   = torch.tensor(maps).float().to(device) \n",
    "params = torch.tensor(params).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073cfb7-21ff-4448-9843-a590060a2e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into train, validation, and test sets\n",
    "batch_size = 200\n",
    "train_frac, valid_frac, test_frac = 0.8, 0.1, 0.1\n",
    "\n",
    "train_dset, valid_dset, test_dset = utils_data.create_datasets(maps, params, \n",
    "                                                               train_frac, valid_frac, test_frac, \n",
    "                                                               seed = seed, \n",
    "                                                               rotations=True)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)\n",
    "test_loader  = DataLoader(test_dset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75d3e60-df78-4c11-b53d-42a7c18b5750",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51f46b-559d-43fc-b33f-7a7119afbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_params = 2 # number of cosmological parameters to predict\n",
    "\n",
    "# hyperparameters\n",
    "lr         = 2e-3\n",
    "epochs     = 200\n",
    "hidden     = 8\n",
    "\n",
    "# output files\n",
    "save_dir = ...\n",
    "fmodel = save_dir + 'model.pt'\n",
    "fout   = save_dir + 'losses.txt'\n",
    "\n",
    "# define the supervised model\n",
    "model = Net(n_params, hidden = hidden).to(device);\n",
    "\n",
    "# define the optimizer and scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=epochs,\n",
    "                                                       eta_min=lr/100, \n",
    "                                                       verbose=verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe79e0-a4f4-4dc3-afe3-83c274296e07",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed7176-b16c-4fd5-b50d-17187cceefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "min_valid_loss, points = 0.0, 0\n",
    "for x, y in valid_loader:\n",
    "    with torch.no_grad():\n",
    "        x    = x.to(device=device)\n",
    "        y    = y.to(device=device)\n",
    "        y_NN = model(x).to(device=device) \n",
    "        #print(y_NN.shape, y.shape, x.shape)\n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).to(device=device).mean()\n",
    "        \n",
    "        min_valid_loss += (loss.cpu().item())*x.shape[0]\n",
    "        points += x.shape[0]\n",
    "        \n",
    "min_valid_loss /= points\n",
    "if verbose:\n",
    "    print('Initial valid loss = %.3e'%min_valid_loss)\n",
    "    \n",
    "# loop over all the epochs\n",
    "for epoch in range(epochs):   \n",
    "    # training\n",
    "    train_loss, num_points = 0.0, 0\n",
    "    model.train()\n",
    "    for x,y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_NN = model(x).to(device=device) \n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += (loss.cpu().item())*x.shape[0]\n",
    "        num_points += x.shape[0]\n",
    "        \n",
    "    train_loss = train_loss/num_points\n",
    "\n",
    "    # validation\n",
    "    valid_loss, num_points = 0.0, 0\n",
    "    model.eval()\n",
    "    for x,y in valid_loader:\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)            \n",
    "            y_NN = model(x).to(device=device) \n",
    "        \n",
    "            y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "            Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "            loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).mean()\n",
    "            \n",
    "            valid_loss += (loss.cpu().item())*x.shape[0]\n",
    "            num_points += x.shape[0]\n",
    "    valid_loss = valid_loss/num_points\n",
    "\n",
    "    # save the model which performs best on validation set\n",
    "    if valid_loss<min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), fmodel)\n",
    "        print('Epoch %d: %.3e %.3e (saved)'%(epoch, train_loss, valid_loss))\n",
    "    else:\n",
    "        print('Epoch %d: %.3e %.3e '%(epoch, train_loss, valid_loss))\n",
    "\n",
    "    if epoch == 0:\n",
    "        f = open(fout, 'w')\n",
    "    else:\n",
    "        f = open(fout, 'a')\n",
    "    f.write('%d %.4e %.4e\\n'%(epoch, train_loss, valid_loss))\n",
    "    f.close()\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7eda2-c972-4190-96ee-0e30f7adf2d8",
   "metadata": {},
   "source": [
    "## Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a76445-4e6b-4ebe-a877-597898bb39bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "losses = np.loadtxt(fout)\n",
    "start_epoch = 10\n",
    "end_epoch = 200\n",
    "plt.ylim(-7, 2)\n",
    "plt.plot(losses[start_epoch:end_epoch, 0], losses[start_epoch:end_epoch, 1], label = 'Training loss')\n",
    "plt.plot(losses[start_epoch:end_epoch, 0], losses[start_epoch:end_epoch, 2], label = 'Validation loss')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51648b-10c6-4375-926b-000b28c3aa39",
   "metadata": {},
   "source": [
    "## Check performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659cda5-2eb6-4484-b1f4-7efd8c5aa11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "model.load_state_dict(torch.load(fmodel))\n",
    "model.eval();\n",
    "\n",
    "test_loss, num_points = 0., 0\n",
    "params_true = []\n",
    "params_pred = []\n",
    "errors_pred = []\n",
    "with torch.no_grad(): \n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_NN = model(x)\n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y, covariance_matrix=Cov).log_prob(y_pred).mean()\n",
    "        \n",
    "        test_loss += (loss.cpu().item())*x.shape[0]\n",
    "        num_points += x.shape[0]\n",
    "        \n",
    "        params_true.append(y)\n",
    "        params_pred.append(y_pred)\n",
    "        errors_pred.append(Cov)\n",
    "    \n",
    "    test_loss = test_loss/num_points\n",
    "print(test_loss)\n",
    "\n",
    "params_true = torch.cat(params_true)\n",
    "params_pred = torch.cat(params_pred)  \n",
    "errors_pred = torch.cat(errors_pred)\n",
    "\n",
    "# compute MSE errors\n",
    "MSE_error = F.mse_loss(params_true[:, :2], params_pred[:, :2]).cpu().numpy()\n",
    "MSE_error = F.mse_loss(params_true[:, :1], params_pred[:, :1]).cpu().numpy()\n",
    "MSE_error = F.mse_loss(params_true[:, 1:], params_pred[:, 1:]).cpu().numpy()\n",
    "print('MSE error: {:}'.format(MSE_error))\n",
    "print('MSE error on OmegaM: {:}'.format(MSE_error))\n",
    "print('MSE error on sigma8: {:}'.format(MSE_error))\n",
    "\n",
    "# predicted errors\n",
    "errors_pred = np.array([torch.sqrt(errors_pred[:, 0, 0]).cpu().numpy(), \n",
    "                        torch.sqrt(errors_pred[:, 1, 1]).cpu().numpy()]).T\n",
    "\n",
    "print('\\nActual errors on A, B (relative, %)')\n",
    "print((torch.abs(params_pred[:, :1] - params_true[:, :1])/params_true[:, :1]).mean()*100)\n",
    "print((torch.abs(params_pred[:, 1:] - params_true[:, 1:])/params_true[:, 1:]).mean()*100)\n",
    "\n",
    "print('\\nPredicted errors on A, B (relative, %)')\n",
    "print((errors_pred[:, 0]/params_pred[:, :1].cpu()).mean()*100)\n",
    "print((errors_pred[:, 1]/params_pred[:, 1:].cpu()).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e4790e-9dfc-4dbd-9d84-3d18499b0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_pred_plot = params_pred.cpu()\n",
    "params_true_plot = params_true.cpu()\n",
    "errors_pred_plot = errors_pred.cpu()\n",
    "\n",
    "# plot results for a subset of test maps\n",
    "params_unique, indices_unique = np.unique(params_pred_plot[:, 0], return_index=True)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(indices_unique)\n",
    "indices_unique = indices_unique[:100]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axs[0].set_ylabel(r'$\\Omega_M$'+', predicted')\n",
    "axs[0].set_xlabel(r'$\\Omega_M$'+', true')\n",
    "axs[0].errorbar(params_true_plot[indices_unique, 0], params_pred_plot[indices_unique, 0], \n",
    "                yerr=errors_pred[indices_unique, 0], \n",
    "                linestyle = '', capsize = 2, label = 'lr = {:.0e}'.format(lr))\n",
    "axs[0].plot([0.15, 0.45], [0.15, 0.45], c = 'k', lw = 2)\n",
    "axs[0].set_aspect('equal')\n",
    "\n",
    "axs[1].set_ylabel(r'$\\sigma_8$'+', predicted')\n",
    "axs[1].set_xlabel(r'$\\sigma_8$'+', true')\n",
    "axs[1].errorbar(params_true_plot[indices_unique, 1], params_pred_plot[indices_unique, 1], \n",
    "                yerr=errors_pred[indices_unique, 1], \n",
    "                linestyle = '', capsize = 2, label = 'lr = {:.0e}'.format(lr))\n",
    "axs[1].plot([0.65, 0.95], [0.65, 0.95], c = 'k', lw = 2)\n",
    "axs[1].set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d1948-7dcf-4a1f-8f57-601e4125d5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc17df2f-0e24-4ff9-b312-b49f9df387ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f5f60-b4c8-4a26-9f4b-93fa8d0bead6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_supervised_env",
   "language": "python",
   "name": "self_supervised_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
