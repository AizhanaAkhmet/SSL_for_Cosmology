{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a5b51a-0468-43f2-829b-3726873a93bd",
   "metadata": {},
   "source": [
    "## Packages and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5152731-e7b3-4ce8-9d4f-c508ad39e9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home11/aakhmetzhanova/.conda/envs/test_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi.utils.get_nn_models import posterior_nn\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from sbi.utils import get_density_thresholder, RestrictedPrior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4452b23-491d-4638-a510-47669540b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from nflows import distributions as distributions_\n",
    "from nflows import flows, transforms\n",
    "from nflows.nn import nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a08c7722-05c6-402b-ae33-0b32fbe3d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "print('Device: %s'%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d926b2-b0a7-4dea-ac9b-1fc507c663c6",
   "metadata": {},
   "source": [
    "## Get the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e178746-a0ee-4660-8d79-fd108e723c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dim = 2\n",
    "low_priors  = torch.tensor([0.15, 0.65])\n",
    "high_priors = torch.tensor([0.45, 0.95])\n",
    "prior = utils.BoxUniform(low= low_priors, high=high_priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c5fd11-01e4-4eac-8b51-e0f35f9a7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_maf(dim=1, num_transforms=8, context_features=None, hidden_features=128):\n",
    "    transform = transforms.CompositeTransform(\n",
    "        [\n",
    "            transforms.CompositeTransform(\n",
    "                [\n",
    "                    transforms.MaskedAffineAutoregressiveTransform(\n",
    "                        features=dim,\n",
    "                        hidden_features=hidden_features,\n",
    "                        context_features=context_features,\n",
    "                        num_blocks=2,\n",
    "                        use_residual_blocks=False,\n",
    "                        random_mask=False,\n",
    "                        activation=torch.tanh,\n",
    "                        dropout_probability=0.0,\n",
    "                        use_batch_norm=False,\n",
    "                    ),\n",
    "                    transforms.RandomPermutation(features=dim),\n",
    "                ]\n",
    "            )\n",
    "            for _ in range(num_transforms)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    distribution = distributions_.StandardNormal((dim,))\n",
    "    neural_net = flows.Flow(transform, distribution)\n",
    "\n",
    "    return neural_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7b6190d-7485-407b-bb84-1bdf588c19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_simulator(theta, num_samples=1):\n",
    "    \"\"\" \n",
    "    Simulator by sampling from the trained normalizing flow\n",
    "    \"\"\"\n",
    "    x = flow_net.sample(num_samples=num_samples, context=theta).detach().numpy()\n",
    "    return torch.tensor(x[:, 0, :])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeacaa01-ff4f-465e-831b-a29fc1886373",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = ...\n",
    "fout   = ...\n",
    "\n",
    "last_layer = 16\n",
    "flow_net = build_maf(dim=last_layer, context_features=2).to(device=device)\n",
    "flow_net.load_state_dict(torch.load(fmodel, map_location=torch.device(device)))\n",
    "flow_net.eval(); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbde81-d465-4bea-95f8-0385d8f65fa2",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7e66d-0810-4aa4-8065-d691bddd2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define observed summary vector s_obs; x_obs is the vector with true parameters\n",
    "x_obs = torch.tensor([0.3, 0.8])\n",
    "s_obs = torch.tensor([-0.0526,  0.0639,  0.1161,  0.1865,  0.2849, -0.2777,  0.0077,  0.0468,\n",
    "        -0.2226,  0.0172,  0.1345, -0.1732, -0.0653,  0.1205, -0.1382, -0.1818])\n",
    "\n",
    "flow_simulator, prior = prepare_for_sbi(flow_simulator, prior)\n",
    "inference = SNPE(prior=prior)\n",
    "\n",
    "posteriors = []\n",
    "proposal = prior\n",
    "num_rounds = 10\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    theta, x = simulate_for_sbi(flow_simulator, proposal, num_simulations=1000)\n",
    "    density_estimator = inference.append_simulations(theta, x, proposal=proposal).train()\n",
    "    \n",
    "    posterior = inference.build_posterior(density_estimator)\n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(s_obs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493821c-b4b9-4db7-878c-2d1ad2bbda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save posteriors from each round as well as the inference summary\n",
    "import os, pickle\n",
    "import numpy as np \n",
    "\n",
    "OmegaM, sigma8 = x_obs[0], x_obs[1]\n",
    "for i in range(num_rounds):\n",
    "    with open(..., \"wb\") as handle: \n",
    "        pickle.dump(posteriors[i], handle)\n",
    "        \n",
    "with open(..., \"wb\") as handle: \n",
    "    pickle.dump(inference.summary, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b76ec1-6df6-4247-89c2-c82f746b518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot samples from posterior\n",
    "posterior_samples = posterior.sample((10000,), x=s_obs)\n",
    "\n",
    "_ = analysis.pairplot(\n",
    "    posterior_samples, limits=[[0.15, 0.45], [0.65, 0.95],], figsize=(5, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa11ab1-e518-4ee3-8c89-448af9a21500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
