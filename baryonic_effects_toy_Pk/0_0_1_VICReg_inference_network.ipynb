{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7adfed9a-cc37-4b37-90ba-b4b221b95d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.functional import F\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils_modules.models import Expander, vector_to_Cov\n",
    "from utils_modules.vicreg import vicreg_loss\n",
    "import utils_modules.data as utils_data\n",
    "import utils_modules.baryons_toy_Pk as utils_toy_Pk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be117552-8914-4a13-a2b4-1eb518887e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot formatting \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 10}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "rcnew = {\"mathtext.fontset\" : \"cm\", \n",
    "         \"xtick.labelsize\" : 18,\n",
    "         \"ytick.labelsize\" : 18,\n",
    "         \"axes.titlesize\" : 26, \n",
    "         \"axes.labelsize\" : 22,\n",
    "         \"xtick.major.size\" : 8,      # major tick size in points\n",
    "         \"xtick.minor.size\" : 4,      # minor tick size in points\n",
    "         \"ytick.major.size\" : 8,      # major tick size in points\n",
    "         \"ytick.minor.size\" : 4,      # minor tick size in points\n",
    "         \"legend.fontsize\" : 22\n",
    "        }\n",
    "plt.rcParams.update(rcnew)\n",
    "plt.style.use('tableau-colorblind10')\n",
    "plt.rcParams.update({\n",
    "  \"text.usetex\": True,\n",
    "})\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d80bb59-c838-45aa-a9c7-9a6a740c74ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# select device; use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: %s'%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416444c-b2d1-437b-8488-7598f33451fb",
   "metadata": {},
   "source": [
    "## Generate parameters and power spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62caf8a1-60ae-4da0-ac26-fe954cfa425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmin  = 7e-3 #h/Mpc\n",
    "kmax = 1\n",
    "\n",
    "kF     = kmin\n",
    "k_bins = int((kmax-kmin)/kF)\n",
    "k      = np.arange(3,k_bins+2)*kF \n",
    "Nk     = 4.0*np.pi*k**2*kF/kF**3  #number of modes in each k-bin\n",
    "\n",
    "# model parameters\n",
    "predict_D     = True\n",
    "Pk_continuous = True #whether fix A_value for kpivot or not\n",
    "\n",
    "dset_size = 1000\n",
    "train_frac, valid_frac, test_frac = 0.8, 0.1, 0.1\n",
    "\n",
    "seed = 1\n",
    "splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c31b16cc-40b7-47e2-b7fb-7f36f0555a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = utils_toy_Pk.generate_params(dset_size, splits, \n",
    "                                                   predict_D = predict_D, \n",
    "                                                   Pk_continuous = Pk_continuous,\n",
    "                                                   seed=seed)\n",
    "params = params.reshape(dset_size, splits, -1)\n",
    "\n",
    "Pk = utils_toy_Pk.get_Pk_arr(k, Nk, params, predict_D = predict_D, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e27e10-2c52-4bbe-ae9d-9f197ada6935",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae7344a-e811-4c51-8431-99aaa8ffee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv, var, cov = 15, 15, 1\n",
    "fmodel = 'trained_models/VICReg_{:d}_{:d}_{:d}.pt'.format(inv, var, cov)\n",
    "fout   = 'trained_models/VICReg_{:d}_{:d}_{:d}.txt'.format(inv, var, cov)\n",
    "    \n",
    "# define the expander model\n",
    "hidden = 16\n",
    "last_layer = 32\n",
    "args_net = [hidden, \n",
    "            last_layer, last_layer, last_layer, \n",
    "            last_layer, last_layer, last_layer]\n",
    "net = Expander(args_net, k.shape[0], bn = True).to(device)\n",
    "net.load_state_dict(torch.load(fmodel))\n",
    "net.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc3cf59-f51c-48a9-be64-f8e8b752665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference netwoek\n",
    "n_params = 3\n",
    "n_tril = int(n_params * (n_params + 1) / 2)  # Number of parameters in lower triangular matrix, for symmetric matrix\n",
    "n_out = n_params + n_tril  # Dummy output of neural network\n",
    "\n",
    "# architecture parameters\n",
    "last_layer = 32\n",
    "mlp_lr_units = [4*last_layer, 4*last_layer, n_out]\n",
    "lr_net = Expander(mlp_lr_units, last_layer, bn = True).to(device)\n",
    "\n",
    "fmodel_lr = fmodel[:-3] + '_inference_network.pt'\n",
    "fout_lr   = fout[:-4] + '_inference_network.txt'\n",
    "\n",
    "# get optimizer and scheduler parameters\n",
    "lr     = 5e-4\n",
    "epochs = 300\n",
    "optimizer = torch.optim.AdamW(lr_net.parameters(), lr=lr, betas=(0.9, 0.999), \n",
    "                             eps=1e-8, amsgrad=False)  \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                       factor=0.3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d3bde-9ce0-442c-8059-d482f2a31226",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb22e0e-dbbc-49bb-ad26-3aa6aac3183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = TensorDataset(torch.tensor(np.log(Pk)), torch.tensor(params))\n",
    "num_params = 4\n",
    "batch_size= 256\n",
    "train_dset, valid_dset, test_dset = torch.utils.data.random_split(dset,\n",
    "                                                                [int(train_frac*dset_size),\n",
    "                                                                 int(valid_frac*dset_size), \n",
    "                                                                 int(test_frac*dset_size)],\n",
    "                                                                 generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "train_dset = TensorDataset(dset.tensors[0][train_dset.indices].reshape(-1, len(k)),\n",
    "                           dset.tensors[1][train_dset.indices].reshape(-1, num_params))\n",
    "valid_dset = TensorDataset(dset.tensors[0][valid_dset.indices].reshape(-1, len(k)),\n",
    "                           dset.tensors[1][valid_dset.indices].reshape(-1, num_params))\n",
    "test_dset = TensorDataset(dset.tensors[0][test_dset.indices].reshape(-1, len(k)),\n",
    "                          dset.tensors[1][test_dset.indices].reshape(-1, num_params))\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)\n",
    "test_loader  = DataLoader(test_dset, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6458d2-7f24-4e4b-88a2-4831e136a756",
   "metadata": {},
   "source": [
    "## Obtain the summaries from the encoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fce67a3-93d8-4d47-8f2a-178c4814c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_valid = []\n",
    "y_valid = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in train_loader:\n",
    "        x    = x.to(device=device).float()\n",
    "        y    = y.to(device=device).float()[:, [0, 1, 3]]\n",
    "        x_NN = net(x).to(device=device)\n",
    "        \n",
    "        x_train.append(x_NN)\n",
    "        y_train.append(y)\n",
    "        \n",
    "    for x, y in valid_loader:\n",
    "        x    = x.to(device=device).float()\n",
    "        y    = y.to(device=device).float()[:, [0, 1, 3]]\n",
    "        x_NN = net(x).to(device=device)\n",
    "        \n",
    "        x_valid.append(x_NN)\n",
    "        y_valid.append(y)\n",
    "\n",
    "############################\n",
    "x_train = torch.cat(x_train)\n",
    "y_train = torch.cat(y_train)\n",
    "\n",
    "train_dset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "############################\n",
    "\n",
    "x_valid = torch.cat(x_valid)\n",
    "y_valid = torch.cat(y_valid)\n",
    "\n",
    "valid_dset = TensorDataset(x_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca1f59-f30c-42d4-a9ed-df5ae71b2e77",
   "metadata": {},
   "source": [
    "## Train the inference network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52dd3b5-833f-422b-a00b-5b1ac927cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=False\n",
    "lr_net.eval()\n",
    "min_valid_loss, points = 0.0, 0\n",
    "for x, y in valid_loader:\n",
    "    with torch.no_grad():\n",
    "        x    = x.to(device=device)\n",
    "        y    = y.to(device=device)[:, :n_params]\n",
    "        y_NN = lr_net(x).to(device=device) \n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).to(device=device).mean()\n",
    "        \n",
    "        min_valid_loss += (loss.cpu().item())*x.shape[0]\n",
    "        points += x.shape[0]\n",
    "        \n",
    "min_valid_loss /= points\n",
    "if verbose:\n",
    "    print('Initial valid loss = %.3e'%min_valid_loss)\n",
    "    \n",
    "# loop over all the epochs\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # training\n",
    "    train_loss, num_points = 0.0, 0\n",
    "    lr_net.train()\n",
    "    for x,y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)[:, :n_params]\n",
    "        y_NN = lr_net(x).to(device=device) \n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += (loss.cpu().item())*x.shape[0]\n",
    "        num_points += x.shape[0]\n",
    "        \n",
    "    train_loss = train_loss/num_points\n",
    "\n",
    "    # validation\n",
    "    valid_loss, num_points = 0.0, 0\n",
    "    lr_net.eval()\n",
    "    for x,y in valid_loader:\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)[:, :n_params]          \n",
    "            y_NN = lr_net(x).to(device=device) \n",
    "        \n",
    "            y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "            Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "            loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).mean()\n",
    "            \n",
    "            valid_loss += (loss.cpu().item())*x.shape[0]\n",
    "            num_points += x.shape[0]\n",
    "    valid_loss = valid_loss/num_points\n",
    "\n",
    "    # verbose\n",
    "    if valid_loss<min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(lr_net.state_dict(), fmodel_lr)\n",
    "        print('Epoch %d: %.3e %.3e (saving)'%(epoch, train_loss, valid_loss))\n",
    "    else:\n",
    "        print('Epoch %d: %.3e %.3e '%(epoch, train_loss, valid_loss))\n",
    "\n",
    "    if epoch == 0:\n",
    "        f = open(fout_lr, 'w')\n",
    "    else:\n",
    "        f = open(fout_lr, 'a')\n",
    "    f.write('%d %.4e %.4e\\n'%(epoch, train_loss, valid_loss))\n",
    "    f.close()\n",
    "    \n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767c554-1790-4c6b-8d86-fe3706885c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.loadtxt(fout_lr)\n",
    "plt.plot(losses[:, 0], losses[:, 1], label = 'Training loss')\n",
    "plt.plot(losses[:, 0], losses[:, 2], label = 'Validation loss')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af72882-513c-4ecc-bb7a-d90fe893df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(fmodel))\n",
    "net.eval();\n",
    "\n",
    "lr_net.load_state_dict(torch.load(fmodel_lr))\n",
    "lr_net.eval(); \n",
    "\n",
    "test_loss, num_points = 0., 0\n",
    "params_true = []\n",
    "params_pred = []\n",
    "errors_pred = []\n",
    "with torch.no_grad(): \n",
    "    for x, y in test_loader:\n",
    "        x = x.float().to(device)\n",
    "        y = y.to(device)[:, [0, 1, 3]]\n",
    "        y_NN = lr_net(net(x))\n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y, covariance_matrix=Cov).log_prob(y_pred).mean()\n",
    "        \n",
    "        test_loss += (loss.cpu().item())*x.shape[0]\n",
    "        num_points += x.shape[0]\n",
    "        \n",
    "        params_true.append(y)\n",
    "        params_pred.append(y_pred)\n",
    "        errors_pred.append(Cov)\n",
    "    \n",
    "    test_loss = test_loss/num_points\n",
    "print(test_loss)\n",
    "params_true = torch.cat(params_true)\n",
    "params_pred = torch.cat(params_pred)\n",
    "errors_pred = torch.cat(errors_pred)\n",
    "\n",
    "MSE_error = F.mse_loss(params_true[:, :2], params_pred[:, :2]).cpu().numpy()\n",
    "print('MSE error: {:}'.format(MSE_error))\n",
    "MSE_error = F.mse_loss(params_true[:, :1], params_pred[:, :1]).cpu().numpy()\n",
    "print('MSE error on OmegaM: {:}'.format(MSE_error))\n",
    "MSE_error = F.mse_loss(params_true[:, 1:2], params_pred[:, 1:2]).cpu().numpy()\n",
    "print('MSE error on sigma8: {:}'.format(MSE_error))\n",
    "\n",
    "print('\\nActual errors on A, B (relative, %)')\n",
    "print((torch.abs(params_pred[:, :1] - params_true[:, :1])/params_true[:, :1]).mean()*100)\n",
    "print(-(torch.abs(params_pred[:, 1:2] - params_true[:, 1:2])/params_true[:, 1:2]).mean()*100)\n",
    "\n",
    "print('\\nPredicted errors on A, B (relative, %)')\n",
    "print((torch.sqrt(errors_pred[:, 0, 0])/params_pred[:, :1]).mean()*100)\n",
    "print(-(torch.sqrt(errors_pred[:, 1, 1])/params_pred[:, 1:2]).mean()*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1dedb-665c-4370-ba0e-c1fc45aa9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(21, 7))\n",
    "\n",
    "axs[0].set_ylabel('A, predicted')\n",
    "axs[0].set_xlabel('A, true')\n",
    "axs[0].errorbar(params_true[:, 0].cpu(), params_pred[:, 0].cpu(), \n",
    "                yerr=torch.sqrt(errors_pred[:, 0, 0]).cpu(), \n",
    "                linestyle = '', capsize = 2, label = r'$1\\sigma$')\n",
    "axs[0].plot([0.1, 1.], [0.1, 1.], c = 'k', lw = 2)\n",
    "axs[0].legend(loc = 'upper left')\n",
    "\n",
    "axs[1].set_ylabel('B, predicted')\n",
    "axs[1].set_xlabel('B, true')\n",
    "axs[1].errorbar(params_true[:, 1].cpu(), params_pred[:, 1].cpu(), \n",
    "                yerr=torch.sqrt(errors_pred[:, 1, 1]).cpu(), \n",
    "                linestyle = '', capsize = 2, label = r'$1\\sigma$')\n",
    "axs[1].plot([-1, 0.], [-1., 0.], c = 'k', lw = 2)\n",
    "axs[1].legend(loc = 'upper left')\n",
    "\n",
    "axs[2].set_ylabel('D, predicted')\n",
    "axs[2].set_xlabel('D, true')\n",
    "axs[2].errorbar(params_true[:, 2].cpu(), params_pred[:, 2].cpu(), \n",
    "                yerr=torch.sqrt(errors_pred[:, 2, 2]).cpu(),\n",
    "                linestyle = '', capsize = 2, label = r'$1\\sigma$')\n",
    "axs[2].legend(loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecd240-7048-476e-998d-fb30b30533b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(24, 7))\n",
    "\n",
    "axs[0].set_ylabel('Predicted A')\n",
    "axs[0].set_xlabel('True A')\n",
    "axs[0].errorbar(params_true[:, 0].cpu(), params_pred[:, 0].cpu(), \n",
    "                yerr=torch.sqrt(errors_pred[:, 0, 0]).cpu(), \n",
    "                linestyle = '', capsize = 2, label = r'$1\\sigma$')\n",
    "axs[0].plot([0.1, 1.], [0.1, 1.], c = 'k', lw = 2)\n",
    "axs[0].legend(loc = 'upper left')\n",
    "axs[0].set_aspect('equal')\n",
    "\n",
    "axs[1].set_ylabel('Predicted B')\n",
    "axs[1].set_xlabel('True B')\n",
    "axs[1].errorbar(params_true[:, 1].cpu(), params_pred[:, 1].cpu(), \n",
    "                yerr=torch.sqrt(errors_pred[:, 1, 1]).cpu(), \n",
    "                linestyle = '', capsize = 2, label = r'$1\\sigma$')\n",
    "axs[1].plot([-1, 0.], [-1., 0.], c = 'k', lw = 2)\n",
    "axs[1].legend(loc = 'upper left')\n",
    "axs[1].set_aspect('equal')\n",
    "\n",
    "axs[2].set_ylabel('Predicted D')\n",
    "axs[2].set_xlabel('True D')\n",
    "axs[2].errorbar(params_true[:, 2].cpu(), params_pred[:, 2].cpu(), \n",
    "                yerr=torch.sqrt(errors_pred[:, 2, 2]).cpu(), \n",
    "                linestyle = '', capsize = 2, label = r'$1\\sigma$')\n",
    "axs[2].plot([-.5, 0.5], [-.5, 0.5], c = 'k', lw = 2)\n",
    "axs[2].legend(loc = 'upper left')\n",
    "axs[2].set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673dbfdd-04ff-49b1-9592-bea60fde7b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e916c-15c9-4d26-a245-2f193baec3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00e34b-736d-4403-a149-524e73a3e127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_supervised_env",
   "language": "python",
   "name": "self_supervised_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
