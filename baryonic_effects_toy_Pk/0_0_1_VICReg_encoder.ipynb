{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7adfed9a-cc37-4b37-90ba-b4b221b95d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.functional import F\n",
    "import torch.nn as nn\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils_modules.models import Expander, vector_to_Cov\n",
    "from utils_modules.vicreg import vicreg_loss\n",
    "import utils_modules.data as utils_data\n",
    "import utils_modules.baryons_toy_Pk as utils_toy_Pk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d80bb59-c838-45aa-a9c7-9a6a740c74ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# select device; use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: %s'%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8416444c-b2d1-437b-8488-7598f33451fb",
   "metadata": {},
   "source": [
    "## Generate parameters and power spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d12cb6-a732-42fd-849b-639b3c69937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmin  = 7e-3 #h/Mpc\n",
    "kmax = 1\n",
    "\n",
    "kF     = kmin\n",
    "k_bins = int((kmax-kmin)/kF)\n",
    "k      = np.arange(3,k_bins+2)*kF \n",
    "Nk     = 4.0*np.pi*k**2*kF/kF**3  #number of modes in each k-bin\n",
    "\n",
    "# model parameters\n",
    "predict_D     = True\n",
    "Pk_continuous = True #whether fix A_value for kpivot or not\n",
    "\n",
    "dset_size = 1000\n",
    "train_frac, valid_frac, test_frac = 0.8, 0.1, 0.1\n",
    "\n",
    "seed = 1\n",
    "splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ca126-23cf-42e9-9af5-5fe331abec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = utils_toy_Pk.generate_params(dset_size, splits, \n",
    "                                      seed = seed,\n",
    "                                      predict_D = predict_D, \n",
    "                                      Pk_continuous = Pk_continuous)\n",
    "params = params.reshape(dset_size, splits, -1)\n",
    "\n",
    "Pk = utils_toy_Pk.get_Pk_arr(k, Nk, params, predict_D = predict_D, seed = seed,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d3bde-9ce0-442c-8059-d482f2a31226",
   "metadata": {},
   "source": [
    "## Train an encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13dbb79-8d6e-489c-bc53-9ef143c3b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fmodel, floss, \n",
    "                 net, mlp_net, \n",
    "                 optimizer, scheduler, \n",
    "                 train_loader, valid_loader,\n",
    "                 epochs, verbose=True,\n",
    "                 inv_weight = 1, var_weight = 0, cov_weight = 0):\n",
    "    \n",
    "    # compute minimum validation loss\n",
    "    net.eval() \n",
    "    mlp_net.eval()\n",
    "    total_loss, points = 0., 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            print(x.shape)\n",
    "            x = x.float().to(device)\n",
    "            bsz = x.shape[0]\n",
    "            \n",
    "            emb_q = mlp_net(net(x[:, 0].contiguous()))\n",
    "            emb_k = mlp_net(net(x[:, 1].contiguous()))\n",
    "            \n",
    "            loss, inv, var, cov = vicreg_loss(emb_q, emb_k, \n",
    "                                              inv_weight, var_weight, cov_weight)\n",
    "            total_loss += loss.detach()*bsz\n",
    "            points += bsz\n",
    "\n",
    "    min_loss_valid = total_loss/points\n",
    "    if verbose: print('Min validation loss: ', min_loss_valid)\n",
    "    \n",
    "    # do a loop over the different epochs\n",
    "    for epoch in range(epochs): \n",
    "        \n",
    "        total_loss, points = 0., 0\n",
    "        inv_loss, var_loss, cov_loss = 0., 0., 0.\n",
    "        \n",
    "        net.train()\n",
    "        mlp_net.train()\n",
    "        for x, y in train_loader:\n",
    "            x = x.float().to(device)\n",
    "            bsz = x.shape[0]\n",
    "            emb_q = mlp_net(net(x[:, 0].contiguous()))\n",
    "            emb_k = mlp_net(net(x[:, 1].contiguous()))\n",
    "            \n",
    "            loss, inv, var, cov = vicreg_loss(emb_q, emb_k, \n",
    "                                              inv_weight, var_weight, cov_weight)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.detach()*bsz\n",
    "            points += bsz\n",
    "            \n",
    "            inv_loss += inv.detach()*bsz\n",
    "            var_loss += var.detach()*bsz\n",
    "            cov_loss += cov.detach()*bsz\n",
    "                \n",
    "        # get the training loss and its components    \n",
    "        loss_train = total_loss/points\n",
    "        inv_loss   = inv_loss/points\n",
    "        var_loss   = var_loss/points\n",
    "        cov_loss   = cov_loss/points\n",
    "               \n",
    "\n",
    "        # validation\n",
    "        net.eval() \n",
    "        mlp_net.eval()\n",
    "        total_loss, points = 0., 0\n",
    "        inv_loss, var_loss, cov_loss = 0., 0., 0.\n",
    "        with torch.no_grad():\n",
    "            for x, y in valid_loader:\n",
    "                x = x.float().to(device)\n",
    "                bsz = x.shape[0]\n",
    "                emb_q = mlp_net(net(x[:, 0].contiguous()))\n",
    "                emb_k = mlp_net(net(x[:, 1].contiguous()))\n",
    "                \n",
    "                loss, inv, var, cov = vicreg_loss(emb_q, emb_k, \n",
    "                                                  inv_weight, var_weight, cov_weight)\n",
    "                total_loss += loss.detach()*bsz\n",
    "                points += bsz\n",
    "                \n",
    "                inv_loss += inv.detach()*bsz\n",
    "                var_loss += var.detach()*bsz\n",
    "                cov_loss += cov.detach()*bsz\n",
    "                \n",
    "        # get the validation loss and its components      \n",
    "        loss_valid = total_loss/points\n",
    "        inv_loss   = inv_loss/points\n",
    "        var_loss   = var_loss/points\n",
    "        cov_loss   = cov_loss/points\n",
    "\n",
    "        # save model if it is better\n",
    "        if loss_valid < min_loss_valid:\n",
    "            if verbose:\n",
    "                print('saving model;  epoch %d; %.4e %.4e'\\\n",
    "                      %(epoch, loss_train, loss_valid))\n",
    "            torch.save(net.state_dict(), fmodel)\n",
    "            min_loss_valid = loss_valid\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('epoch %d; %.4e %.4e'\\\n",
    "                      %(epoch,loss_train,loss_valid))\n",
    "\n",
    "        if epoch == 0:\n",
    "            f = open(fout, 'w')\n",
    "        else:\n",
    "            f = open(fout, 'a')\n",
    "        f.write('%d %.4e %.4e %.4e %.4e %.4e\\n'%(epoch, loss_train, loss_valid, \n",
    "                                                 inv_loss, var_loss, cov_loss))\n",
    "        f.close()\n",
    "        scheduler.step(loss_valid)\n",
    "        \n",
    "    return net, mlp_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d26dd-5866-405b-a6bd-978f81a6e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "epochs           = 500\n",
    "batch_size       = 256\n",
    "\n",
    "dset = utils_toy_Pk.customDataset(torch.tensor(np.log(Pk)), \n",
    "                                  torch.tensor(params), \n",
    "                                  utils_toy_Pk.AugmentationTransformations())\n",
    "train_dset, valid_dset, test_dset = torch.utils.data.random_split(dset,\n",
    "                                                                [int(train_frac*dset_size),\n",
    "                                                                 int(valid_frac*dset_size), \n",
    "                                                                 int(test_frac*dset_size)],\n",
    "                                                                 generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)\n",
    "test_loader  = DataLoader(test_dset, batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e0ff3-aacf-4efd-86f3-def4ea7655e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv, var, cov = 15, 15, 1\n",
    "fmodel = 'trained_models/VICReg_{:d}_{:d}_{:d}.pt'.format(inv, var, cov)\n",
    "fout   = 'trained_models/VICReg_{:d}_{:d}_{:d}.txt'.format(inv, var, cov)\n",
    "    \n",
    "# define the expander model\n",
    "hidden = 16\n",
    "last_layer = 32\n",
    "args_net = [hidden, \n",
    "            last_layer, last_layer, last_layer, \n",
    "            last_layer, last_layer, last_layer]\n",
    "net = Expander(args_net, k.shape[0], bn = True).to(device)\n",
    "\n",
    "# define the expander model\n",
    "mlp_exp_units = [4*last_layer, 4*last_layer, 4*last_layer]\n",
    "inference_net = Expander(mlp_exp_units, last_layer, bn = True).to(device)\n",
    "\n",
    "\n",
    "# define the optimizer\n",
    "lr = 1e-3\n",
    "wd = 0.\n",
    "\n",
    "optimizer = torch.optim.Adam([*net.parameters(), *inference_net.parameters()], \n",
    "                                 lr=lr, betas=(0.9, 0.999),\n",
    "                                 eps=1e-8, amsgrad=False, weight_decay=wd)  \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb480846-c1d5-40a3-b13c-a620db221236",
   "metadata": {},
   "outputs": [],
   "source": [
    "net, mlp = run_training(fmodel, fout, net, inference_net, \n",
    "                        optimizer, scheduler, \n",
    "                        train_loader, valid_loader,\n",
    "                        inv_weight = inv, var_weight = var, cov_weight = cov,\n",
    "                        epochs = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e1c35-9d5f-41a6-9819-47023d722f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.loadtxt(fout)\n",
    "plt.plot(losses[:, 0], losses[:, 1], label = 'Training loss')\n",
    "plt.plot(losses[:, 0], losses[:, 2], label = 'Validation loss')\n",
    "plt.legend(loc = 'best')\n",
    "print(losses[:, 1].min(), losses[:, 2].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e916c-15c9-4d26-a245-2f193baec3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00e34b-736d-4403-a149-524e73a3e127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_supervised_env",
   "language": "python",
   "name": "self_supervised_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
