{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b45daa-3765-4a7f-a7fa-e9681b260c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils_modules.models import SummaryNet, Expander, Net, vector_to_Cov\n",
    "from utils_modules.vicreg import vicreg_loss, vicreg_loss_pairs\n",
    "import utils_modules.data as utils_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173babf-4406-4110-a779-c69fcde19bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: %s'%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f65f4cf-e5e3-45a7-8a0b-23d89db5d0e9",
   "metadata": {},
   "source": [
    "## Load maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f0903-246d-4b4e-8f0e-3f845303eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load maps and parameters\n",
    "n_params = 2\n",
    "home_dir = ... # maps and parameters directory\n",
    "maps   = np.load(home_dir + 'Maps_Mtot_SIMBA_LH_z=0.00.npy')\n",
    "dset_size = 1000 # data set size\n",
    "splits    = 15   # number of realizations per parameter set\n",
    "maps_size = maps.shape[-1]\n",
    "maps   = maps.reshape(dset_size, splits, 1, maps_size, maps_size) # prepare maps for VICReg\n",
    "\n",
    "params = np.loadtxt(home_dir + 'params_SIMBA.txt')[:, None, :n_params]\n",
    "params  = np.repeat(params, splits, axis = 1) # reshape the parameters to match the shape of the maps\n",
    "minimum = np.array([0.1, 0.6])\n",
    "maximum = np.array([0.5, 1.0])\n",
    "params  = (params - minimum)/(maximum - minimum) # rescale parameters\n",
    "\n",
    "# pre-process the maps data set\n",
    "rescale     = True\n",
    "standardize = True\n",
    "verbose     = True\n",
    "\n",
    "if rescale:\n",
    "    maps = np.log10(maps)\n",
    "if standardize:\n",
    "    maps_mean, maps_std = np.mean(maps, dtype=np.float64), np.std(maps, dtype=np.float64)\n",
    "    maps = (maps - maps_mean)/maps_std\n",
    "    \n",
    "if verbose:\n",
    "    print('Shape of parameters and maps:', params.shape, maps.shape)\n",
    "    print('Parameter 1 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 0].min(), params[:, :, 0].max()))\n",
    "    print('Parameter 2 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 1].min(), params[:, :, 1].max()))\n",
    "    \n",
    "    if rescale: print('Rescale: ', rescale)\n",
    "    if standardize: print('Standardize: ', standardize)\n",
    "\n",
    "maps   = torch.tensor(maps).float().to(device) \n",
    "params = torch.tensor(params).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23456873-9863-4eb8-a762-7a0eec85a7a3",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3829764-4f2e-4df1-a6e2-e5da460b65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir    = ...\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1027c38a-ebaa-42ca-b9f3-4f53f96a09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss is taken from\n",
    "# https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial17/SimCLR.html\n",
    "def nce_loss(features, temperature=0.1):\n",
    "    # Calculate cosine similarity\n",
    "    cos_sim = F.cosine_similarity(features[:,None,:], features[None,:,:], dim=-1)\n",
    "    # Mask out cosine similarity to itself\n",
    "    self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "    cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    # Find positive example -> batch_size//2 away from the original example\n",
    "    pos_mask = self_mask.roll(shifts=cos_sim.shape[0]//2, dims=0)\n",
    "    # InfoNCE loss\n",
    "    cos_sim = cos_sim / temperature\n",
    "    nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "    nll = nll.mean()\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef014e5-5868-41d8-bc76-264e6671be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fmodel, floss, \n",
    "                 net, mlp_net, \n",
    "                 optimizer, scheduler, \n",
    "                 train_loader, valid_loader,\n",
    "                 epochs, verbose=True,\n",
    "                 temperature = 0.1):\n",
    "    \n",
    "    # compute minimum validation loss\n",
    "    net.eval() \n",
    "    mlp_net.eval()\n",
    "    total_loss, points = 0., 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            #print(x.shape)\n",
    "            bsz, n_views, n_channels, img_shape1, img_shape2 = x.shape\n",
    "            \n",
    "            # combine the two views into one dataset\n",
    "            imgs = torch.cat((x[:, 0], x[:, 1]), dim=0)\n",
    "            print(imgs.shape)\n",
    "            # Encode all images\n",
    "            feats = mlp_net(net(imgs))\n",
    "            # Compute loss function\n",
    "            loss=nce_loss(feats, temperature)\n",
    "            \n",
    "            total_loss += loss.detach()*bsz\n",
    "            points += bsz\n",
    "\n",
    "    min_loss_valid = total_loss/points\n",
    "    if verbose: print('Min validation loss: ', min_loss_valid)\n",
    "    \n",
    "    # do a loop over the different epochs\n",
    "    for epoch in range(epochs): \n",
    "        \n",
    "        total_loss, points = 0., 0\n",
    "        \n",
    "        net.train()\n",
    "        mlp_net.train()\n",
    "        for x, y in train_loader:\n",
    "            x = x.float().to(device)\n",
    "            bsz, n_views, n_channels, img_shape1, img_shape2 = x.shape\n",
    "            \n",
    "            # combine the two views into one dataset\n",
    "            imgs = torch.cat((x[:, 0], x[:, 1]), dim=0)\n",
    "            # Encode all images\n",
    "            feats = mlp_net(net(imgs))\n",
    "            # Compute loss function\n",
    "            loss=nce_loss(feats, temperature)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.detach()*bsz\n",
    "            points += bsz\n",
    "                \n",
    "        # get the training loss and its components    \n",
    "        loss_train = total_loss/points       \n",
    "\n",
    "        # validation\n",
    "        net.eval() \n",
    "        mlp_net.eval()\n",
    "        total_loss, points = 0., 0\n",
    "        inv_loss, var_loss, cov_loss = 0., 0., 0.\n",
    "        with torch.no_grad():\n",
    "            for x, y in valid_loader:\n",
    "                x = x.float().to(device)\n",
    "                bsz, n_views, n_channels, img_shape1, img_shape2 = x.shape\n",
    "                # combine the two views into one dataset\n",
    "                imgs = torch.cat((x[:, 0], x[:, 1]), dim=0)\n",
    "                # Encode all images\n",
    "                feats = mlp_net(net(imgs))\n",
    "                # Compute loss function\n",
    "                loss=nce_loss(feats, temperature)\n",
    "                \n",
    "                total_loss += loss.detach()*bsz\n",
    "                points += bsz\n",
    "                \n",
    "                \n",
    "        # get the validation loss and its components      \n",
    "        loss_valid = total_loss/points\n",
    "    \n",
    "        # save model if it is better\n",
    "        if loss_valid < min_loss_valid:\n",
    "            if verbose:\n",
    "                print('saving model;  epoch %d; %.4e %.4e'\\\n",
    "                      %(epoch, loss_train, loss_valid))\n",
    "            torch.save(net.state_dict(), fmodel)\n",
    "            min_loss_valid = loss_valid\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('epoch %d; %.4e %.4e'\\\n",
    "                      %(epoch,loss_train,loss_valid))\n",
    "\n",
    "        if epoch == 0:\n",
    "            f = open(fout, 'w')\n",
    "        else:\n",
    "            f = open(fout, 'a')\n",
    "        f.write('%d %.4e %.4e \\n'%(epoch, loss_train, loss_valid))\n",
    "        f.close()\n",
    "        scheduler.step(loss_valid)\n",
    "        \n",
    "    return net, mlp_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226604d-45d7-4d94-ae67-7cc309130be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into train, validation, and test sets\n",
    "batch_size = 256\n",
    "temp = 0.1\n",
    "train_frac, valid_frac, test_frac = 0.7, 0.2, 0.1\n",
    "\n",
    "\n",
    "train_dset, valid_dset, test_dset = utils_data.create_datasets(maps, params, \n",
    "                                                    train_frac, valid_frac, test_frac, \n",
    "                                                    seed = seed, VICReg=True)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)\n",
    "test_loader  = DataLoader(test_dset, batch_size, shuffle = False)\n",
    "###################\n",
    "lr         = 1e-3\n",
    "epochs     = 150\n",
    "# define the model\n",
    "last_layer = 128\n",
    "\n",
    "model = torchvision.models.resnet18(num_classes=last_layer)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.to(device);\n",
    "\n",
    "# define the expander model\n",
    "mlp_exp_units = [4*last_layer, 4*last_layer]\n",
    "expander_net = Expander(mlp_exp_units, last_layer, bn = True).to(device)\n",
    "\n",
    "# define the optimizer, scheduler\n",
    "optimizer = torch.optim.AdamW([*model.parameters(), *expander_net.parameters()], \n",
    "                                  lr=lr, betas=(0.9, 0.999), eps=1e-8, amsgrad=False)  \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                           factor=0.3,verbose=True)\n",
    "temp = 0.1\n",
    "\n",
    "fmodel = save_dir + 'SimCLR_T_{:.3f}_bs_{:d}_{:d}hl_{:d}.pt'.format(temp, batch_size,\n",
    "                                                                    len(mlp_exp_units), \n",
    "                                                                     last_layer)\n",
    "fout   = save_dir + 'SimCLR_T_{:.3f}_bs_{:d}_{:d}hl_{:d}.txt'.format(temp, batch_size,\n",
    "                                                                     len(mlp_exp_units), \n",
    "                                                                     last_layer)\n",
    "net, mlp = run_training(fmodel, fout, model, expander_net, optimizer, scheduler, \n",
    "                                    train_loader, valid_loader, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484b6bd-4b2b-441b-9806-19af4f6c89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = np.loadtxt(fout)\n",
    "start_epoch = 0\n",
    "plt.plot(losses[start_epoch:, 0], losses[start_epoch:, 1], label = 'Training loss')\n",
    "plt.plot(losses[start_epoch:, 0], losses[start_epoch:, 2], label = 'Validation loss')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5b07c-e5b2-4ac7-929c-f757e27f97e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb91ac-94ab-4bd4-9746-da94aadfd343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_supervised_env",
   "language": "python",
   "name": "self_supervised_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
