{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7997412-3a1e-4b52-9600-3e498ac92a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.functional import F\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torchvision\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils_modules.models import SummaryNet, Expander, Net, NetEquivalent, vector_to_Cov\n",
    "from utils_modules.vicreg import vicreg_loss\n",
    "import utils_modules.data as utils_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c672a-4c7f-42e2-9d7b-29d31f035c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: %s'%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc4ecca-6c6e-478b-9346-9ee91b62f7f3",
   "metadata": {},
   "source": [
    "## Load maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b853fb9-7ecf-499d-b483-7d392062ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load maps and parameters\n",
    "n_params = 2\n",
    "home_dir = ... # maps and parameters directory\n",
    "maps   = np.load(home_dir + 'Maps_Mtot_SIMBA_LH_z=0.00.npy')\n",
    "dset_size = 1000 # data set size\n",
    "splits    = 15   # number of realizations per parameter set\n",
    "maps_size = maps.shape[-1]\n",
    "maps   = maps.reshape(dset_size, splits, 1, maps_size, maps_size) # prepare maps for VICReg\n",
    "\n",
    "params = np.loadtxt(home_dir + 'params_SIMBA.txt')[:, None, :n_params]\n",
    "params  = np.repeat(params, splits, axis = 1) # reshape the parameters to match the shape of the maps\n",
    "minimum = np.array([0.1, 0.6])\n",
    "maximum = np.array([0.5, 1.0])\n",
    "params  = (params - minimum)/(maximum - minimum) # rescale parameters\n",
    "\n",
    "# pre-process the maps data set\n",
    "rescale     = True\n",
    "standardize = True\n",
    "verbose     = True\n",
    "\n",
    "if rescale:\n",
    "    maps = np.log10(maps)\n",
    "if standardize:\n",
    "    maps_mean, maps_std = np.mean(maps, dtype=np.float64), np.std(maps, dtype=np.float64)\n",
    "    maps = (maps - maps_mean)/maps_std\n",
    "    \n",
    "if verbose:\n",
    "    print('Shape of parameters and maps:', params.shape, maps.shape)\n",
    "    print('Parameter 1 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 0].min(), params[:, :, 0].max()))\n",
    "    print('Parameter 2 range of values: [{:.3f}, {:.3f}]'.format(params[:, :, 1].min(), params[:, :, 1].max()))\n",
    "    \n",
    "    if rescale: print('Rescale: ', rescale)\n",
    "    if standardize: print('Standardize: ', standardize)\n",
    "\n",
    "maps   = torch.tensor(maps).float().to(device) \n",
    "params = torch.tensor(params).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a724b440-eece-4b52-af92-601ac6c63df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into train, validation, and test sets\n",
    "batch_size = 150\n",
    "train_frac, valid_frac, test_frac = 0.7, 0.2, 0.1\n",
    "seed = 1\n",
    "train_dset, valid_dset, test_dset = utils_data.create_datasets(maps, params, \n",
    "                                                               train_frac, valid_frac, test_frac, \n",
    "                                                               seed = seed, \n",
    "                                                               rotations=True) \n",
    "\n",
    "train_loader = DataLoader(train_dset, batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_dset, batch_size, shuffle = True)\n",
    "test_loader  = DataLoader(test_dset, batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75d3e60-df78-4c11-b53d-42a7c18b5750",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ca3e5b-8c89-44b1-aa5a-3973b5efa127",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir    = ...\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    if verbose: print('\\n Saving to: ', save_dir)\n",
    "n_params = 2\n",
    "n_tril = int(n_params * (n_params + 1) / 2)  \n",
    "n_total = n_params + n_tril\n",
    "\n",
    "lr         = 2e-4\n",
    "eta_min    = lr/100\n",
    "epochs     = 200    \n",
    "\n",
    "fmodel = save_dir + 'model.pt'\n",
    "fout   = save_dir + 'losses.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3518e40-a8d6-4fae-87aa-5c84d34ae9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = torchvision.models.resnet18(num_classes=n_total)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.to(device);\n",
    "\n",
    "# define the optimizer, scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=epochs, \n",
    "                                                       eta_min=eta_min, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6e365-e32b-4bcf-9dd6-2a662c616fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "min_valid_loss, points = 0.0, 0\n",
    "for x, y in valid_loader:\n",
    "    with torch.no_grad():\n",
    "        x    = x.to(device=device)\n",
    "        y    = y.to(device=device)\n",
    "        y_NN = model(x).to(device=device) \n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).to(device=device).mean()\n",
    "        \n",
    "        min_valid_loss += (loss.cpu().item())*x.shape[0]\n",
    "        points += x.shape[0]\n",
    "        \n",
    "min_valid_loss /= points\n",
    "if verbose:\n",
    "    print('Initial valid loss = %.3e'%min_valid_loss)\n",
    "    \n",
    "# loop over the epochs\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # training\n",
    "    train_loss, num_points = 0.0, 0\n",
    "    model.train()\n",
    "    for x,y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_NN = model(x).to(device=device) \n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).mean()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += (loss.cpu().item())*x.shape[0]\n",
    "        num_points += x.shape[0]\n",
    "        \n",
    "    train_loss = train_loss/num_points\n",
    "\n",
    "    # validation\n",
    "    valid_loss, num_points = 0.0, 0\n",
    "    model.eval()\n",
    "    for x,y in valid_loader:\n",
    "        with torch.no_grad():\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)            \n",
    "            y_NN = model(x).to(device=device) \n",
    "        \n",
    "            y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "            Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "            loss = -dist.MultivariateNormal(loc=y_pred, covariance_matrix=Cov).log_prob(y).mean()\n",
    "            \n",
    "            valid_loss += (loss.cpu().item())*x.shape[0]\n",
    "            num_points += x.shape[0]\n",
    "    valid_loss = valid_loss/num_points\n",
    "\n",
    "    # verbose\n",
    "    if valid_loss<min_valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), fmodel)\n",
    "        print('Epoch %d: %.3e %.3e (saving)'%(epoch, train_loss, valid_loss))\n",
    "    else:\n",
    "        print('Epoch %d: %.3e %.3e '%(epoch, train_loss, valid_loss))\n",
    "\n",
    "    if epoch == 0:\n",
    "        f = open(fout, 'w')\n",
    "    else:\n",
    "        f = open(fout, 'a')\n",
    "    f.write('%d %.4e %.4e\\n'%(epoch, train_loss, valid_loss))\n",
    "    f.close()\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f85181-b0ac-4d8c-ba45-e1e81199b95d",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b143dc-cb0d-47a0-924b-90b18898d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "losses = np.loadtxt(fout)\n",
    "start_epoch = 0\n",
    "end_epoch   = -1\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.ylim(-7, 7)\n",
    "plt.plot(losses[start_epoch:end_epoch, 0], losses[start_epoch:end_epoch, 1], label = 'Training loss')\n",
    "plt.plot(losses[start_epoch:end_epoch, 0], losses[start_epoch:end_epoch, 2], label = 'Validation loss')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d54a4-647a-4623-94d8-d32d564589fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss on the test set\n",
    "model.load_state_dict(torch.load(fmodel))\n",
    "model.eval();\n",
    "\n",
    "test_loss, num_points = 0., 0\n",
    "params_true = []\n",
    "params_pred = []\n",
    "errors_pred = []\n",
    "with torch.no_grad(): \n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_NN = model(x)\n",
    "        \n",
    "        y_pred, cov_pred = y_NN[:, :n_params], y_NN[:, n_params:]\n",
    "        Cov = vector_to_Cov(cov_pred.cpu()).to(device=device)\n",
    "        loss = -dist.MultivariateNormal(loc=y, covariance_matrix=Cov).log_prob(y_pred).mean()\n",
    "        \n",
    "        test_loss += (loss.cpu().item())*x.shape[0]\n",
    "        num_points += x.shape[0]\n",
    "        \n",
    "        params_true.append(y)\n",
    "        params_pred.append(y_pred)\n",
    "        errors_pred.append(Cov)\n",
    "    \n",
    "    test_loss = test_loss/num_points\n",
    "print(test_loss)\n",
    "\n",
    "params_true = torch.cat(params_true)\n",
    "params_pred = torch.cat(params_pred)  \n",
    "errors_pred = torch.cat(errors_pred)\n",
    "\n",
    "delta_scale = maximum - minimum\n",
    "params_true = params_true.cpu()*(maximum - minimum) + minimum\n",
    "params_pred = params_pred.cpu()*(maximum - minimum) + minimum  \n",
    "errors_pred = np.array([torch.sqrt(errors_pred[:, 0, 0]).cpu().numpy()*delta_scale[0], \n",
    "                        torch.sqrt(errors_pred[:, 1, 1]).cpu().numpy()*delta_scale[1]]).T\n",
    "\n",
    "\n",
    "\n",
    "MSE_error = F.mse_loss(params_true[:, :2], params_pred[:, :2]).cpu().numpy()\n",
    "print('MSE error: {:}'.format(MSE_error))\n",
    "MSE_error = F.mse_loss(params_true[:, :1], params_pred[:, :1]).cpu().numpy()\n",
    "print('MSE error on OmegaM: {:}'.format(MSE_error))\n",
    "MSE_error = F.mse_loss(params_true[:, 1:], params_pred[:, 1:]).cpu().numpy()\n",
    "print('MSE error on sigma8: {:}'.format(MSE_error))\n",
    "\n",
    "print('\\nActual errors on A, B (relative, %)')\n",
    "print((torch.abs(params_pred[:, :1] - params_true[:, :1])/params_true[:, :1]).mean()*100)\n",
    "print((torch.abs(params_pred[:, 1:] - params_true[:, 1:])/params_true[:, 1:]).mean()*100)\n",
    "\n",
    "print('\\nPredicted errors on A, B (relative, %)')\n",
    "print((errors_pred[:, 0]/params_pred[:, :1].cpu()).mean()*100)\n",
    "print((errors_pred[:, 1]/params_pred[:, 1:].cpu()).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8c421-9a49-4384-bc2a-3c7f2dd23824",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_pred_plot = params_pred.cpu()\n",
    "params_true_plot = params_true.cpu()\n",
    "\n",
    "params_unique, indices_unique = np.unique(params_true_plot[:, 0], return_index=True)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(indices_unique)\n",
    "indices_unique = indices_unique[:100]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axs[0].set_ylabel(r'$\\Omega_M$'+', predicted')\n",
    "axs[0].set_xlabel(r'$\\Omega_M$'+', true')\n",
    "axs[0].errorbar(params_true_plot[indices_unique, 0], params_pred_plot[indices_unique, 0], \n",
    "                yerr=errors_pred[indices_unique, 0], \n",
    "                linestyle = '', capsize = 2, label =  r'$1\\sigma$')\n",
    "axs[0].plot([0.1, 0.5], [0.1, 0.5], c = 'k', lw = 2)\n",
    "axs[0].legend(loc='best')\n",
    "axs[0].set_aspect('equal')\n",
    "\n",
    "axs[1].set_ylabel(r'$\\sigma_8$'+', predicted')\n",
    "axs[1].set_xlabel(r'$\\sigma_8$'+', true')\n",
    "axs[1].errorbar(params_true_plot[indices_unique, 1], params_pred_plot[indices_unique, 1], \n",
    "                yerr=errors_pred[indices_unique, 1], \n",
    "                linestyle = '', capsize = 2, label = r'$1\\sigma$')\n",
    "axs[1].plot([0.6, 1.], [0.6, 1.], c = 'k', lw = 2)\n",
    "axs[1].set_aspect('equal')\n",
    "axs[1].legend(loc='best')\n",
    "plt.savefig(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f5f60-b4c8-4a26-9f4b-93fa8d0bead6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_supervised_env",
   "language": "python",
   "name": "self_supervised_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
